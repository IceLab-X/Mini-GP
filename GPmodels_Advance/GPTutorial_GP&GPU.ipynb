{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Author: Zidong Chen\n",
    "\n",
    "Date:2024/07/04\n",
    "\n",
    "Introduction\n",
    "\n",
    "With the advancement of hardware technology, leveraging GPUs for parallel computing in Gaussian processes has become a prominent question. After significant progress in developing scalable GP models, I am excited to introduce a new inference method for standard Gaussian processes that enables GPU acceleration. This method allows for training exact Gaussian processes with thousands of data points in seconds, using just a single GPU on a laptop.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent folder to sys.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from data_sample import generate_example_data as data\n",
    "from core.cigp_v10 import cigp\n",
    "# from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from core.kernel import ARDKernel\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # Fixing strange error if run in MacOS\n",
    "JITTER = 1e-3\n",
    "EPS = 1e-10\n",
    "PI = 3.1416"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:36.913672900Z",
     "start_time": "2024-07-25T03:58:34.137493800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In standard Gaussian process, the negative log likelihood is given by:\n",
    "$$-L=\\frac{1}{2}y^T\\Sigma^{-1}y+\\frac{1}{2}log(|\\Sigma|)+\\frac{n}{2}log(2\\pi)$$\n",
    "Where$\\Sigma = K(X,X)+ \\frac{1}{\\beta} I$, normally we compute the inverse of $\\Sigma$ using Cholesky decomposition, which requires $O(n^3)$ time complexity. Here we use the conjugate gradient method to solve the linear system $\\Sigma \\cdot x = y$, which gives us x=$\\Sigma^{-1} \\cdot y$. The [conjugate gradient](https://en.wikipedia.org/wiki/Conjugate_gradient_method) is an iterative method, which is more suitable for large-scale data. And the time complexity is $O(n^2 t_\\epsilon)$ with $t_\\epsilon$ equals to the number of iterations required for the algorithm to converge to a solution within a tolerance level $\\epsilon$, and $t_\\epsilon \\ll n$ for large $n$.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def conjugate_gradient(A, b, x0=None, tol=1e-1, max_iter=1000):\n",
    "    if x0 is None:\n",
    "        x = torch.zeros_like(b)\n",
    "    else:\n",
    "        x = x0\n",
    "    r = b - torch.matmul(A, x)\n",
    "    p = r.clone()\n",
    "    rsold = torch.dot(r.flatten(), r.flatten())\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Ap = torch.matmul(A, p)\n",
    "        alpha = rsold / torch.dot(p.flatten(), Ap.flatten())\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        rsnew = torch.dot(r.flatten(), r.flatten())\n",
    "\n",
    "        if torch.sqrt(rsnew) < tol:\n",
    "            break\n",
    "\n",
    "        p = r + (rsnew / rsold) * p\n",
    "        rsold = rsnew\n",
    "\n",
    "        #if i % 10 == 0:  # Print diagnostics every 10 iterations\n",
    "            #print(f\"Iteration {i}: Residual norm {torch.sqrt(rsnew):.6e}\")\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def cholesky_solve(A, b):\n",
    "    # Perform Cholesky decomposition (A = LL^T)\n",
    "    L = torch.linalg.cholesky(A)\n",
    "\n",
    "    # Solve Ax = b using torch.cholesky_solve\n",
    "    x = torch.cholesky_solve(b, L)\n",
    "\n",
    "    return x\n",
    "# Verify the solutions\n",
    "def verify_solution(A, b, x):\n",
    "    residual = b - torch.matmul(A, x)\n",
    "    residual_norm = torch.norm(residual)\n",
    "    return residual_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:39.353133200Z",
     "start_time": "2024-07-25T03:58:39.314715100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# generate example data\n",
    "xtr, ytr,xte,yte = data.generate(2000,100,seed=42)\n",
    "xtr = xtr.to(dtype=torch.float64,device=device)\n",
    "ytr = ytr.to(dtype=torch.float64, device=device)\n",
    "xte = xte.to(dtype=torch.float64,device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:50.162343500Z",
     "start_time": "2024-07-25T03:58:50.154845300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "kernel= ARDKernel(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:51.750593700Z",
     "start_time": "2024-07-25T03:58:51.746793200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "log_beta = nn.Parameter(torch.ones(1, dtype=torch.float64, device=device) * -4)\n",
    " # this is a large noise. we optimize to shrink it to a proper value."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:52.242129400Z",
     "start_time": "2024-07-25T03:58:52.232052100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us compare the performance of using conjugate_gradient and cholesky decomposition to solve the linear system $\\Sigma \\cdot x=y$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Sigma = kernel(xtr, xtr) + torch.eye(xtr.size(0), device=device) * torch.exp(log_beta) + JITTER * torch.eye(xtr.size(0), device=device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:58:57.230475200Z",
     "start_time": "2024-07-25T03:58:54.156139400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugate Gradient Solution Time: 0.015179 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "x_cg=conjugate_gradient(Sigma,ytr)\n",
    "time_cg = time.time() - start_time\n",
    "print(f\"Conjugate Gradient Solution Time: {time_cg:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:00.329199400Z",
     "start_time": "2024-07-25T03:59:00.291122100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky Solution Time: 1.117507 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "x_cholesky=cholesky_solve(Sigma,ytr)\n",
    "time_cholesky = time.time() - start_time\n",
    "print(f\"Cholesky Solution Time: {time_cholesky:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:01.604314300Z",
     "start_time": "2024-07-25T03:59:00.480239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugate Gradient Residual Norm: 3.791568e-03\n",
      "Cholesky Residual Norm: 8.506846e-10\n"
     ]
    }
   ],
   "source": [
    "residual_norm_cg=verify_solution(Sigma, ytr, x_cg)\n",
    "residual_norm_cholesky=verify_solution(Sigma, ytr, x_cholesky)\n",
    "print(f\"Conjugate Gradient Residual Norm: {residual_norm_cg:.6e}\")\n",
    "print(f\"Cholesky Residual Norm: {residual_norm_cholesky:.6e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:01.666910600Z",
     "start_time": "2024-07-25T03:59:01.606315200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from the above results, the Conjugate Gradient method solves the linear system much faster than Cholesky decomposition with acceptable accuracy. Users can set a smaller tolerance for better accuracy, but due to floating-point errors, this is often unnecessary. The next challenge is to solve for the log determinant of the covariance matrix, here we propose a numerically stable version of [Lanczos algorithm for quadratic forms](https://shashankaubaru.github.io/Papers/Lanc_Quad.pdf)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def lanc_quad_logdet(A, m=10, nvecs=10):\n",
    "    \"\"\"\n",
    "    Estimate the log-determinant of a symmetric positive definite matrix using\n",
    "    the Stochastic Lanczos Quadrature (SLQ) method.\n",
    "\n",
    "    Parameters:\n",
    "    A (torch.Tensor): The symmetric positive definite input matrix.\n",
    "    m (int): Number of Lanczos steps (degree).\n",
    "    nvecs (int): Number of starting vectors.\n",
    "\n",
    "    Returns:\n",
    "    z1 mean: The average of estimates for starting vectors.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    z1 = torch.zeros(nvecs, dtype=A.dtype, device=A.device)\n",
    "\n",
    "    for ii in range(nvecs):\n",
    "        w = torch.sign(torch.randn(n, dtype=A.dtype, device=A.device))  # Random Rademacher vector\n",
    "        v0 = w / torch.norm(w)\n",
    "        #print(torch.norm(w))\n",
    "        # Lanczos algorithm\n",
    "        V = torch.zeros((n, m), dtype=A.dtype, device=A.device)\n",
    "        alpha = torch.zeros(m, dtype=A.dtype, device=A.device)\n",
    "        beta = torch.zeros(m-1, dtype=A.dtype, device=A.device)\n",
    "        V[:, 0] = v0.clone()\n",
    "\n",
    "\n",
    "        w = A @ V[:, 0].clone()\n",
    "        #print(A)\n",
    "        alpha[0] = torch.dot(V[:, 0].clone(), w)\n",
    "        w = w - alpha[0].clone() * V[:, 0].clone()\n",
    "\n",
    "        for j in range(1, m):\n",
    "            beta[j-1] = torch.norm(w)\n",
    "            if beta[j-1] != 0:\n",
    "                V[:, j] = w / beta[j-1].clone()\n",
    "                w = A @ V[:, j].clone() - beta[j-1].clone() * V[:, j-1].clone()\n",
    "                alpha[j] = torch.dot(V[:, j].clone(), w)\n",
    "                w = w - alpha[j].clone() * V[:, j].clone()\n",
    "\n",
    "        H = torch.diag(alpha) + torch.diag(beta, 1) + torch.diag(beta, -1)\n",
    "        #print(V[:, j])\n",
    "        #print(w)\n",
    "        #print(torch.diag(alpha),torch.diag(beta, 1),torch.diag(beta, -1))\n",
    "        #print(H)\n",
    "        eigvals, eigvecs = torch.linalg.eig(H)\n",
    "        #print(eigvals)\n",
    "        theta = torch.abs(eigvals)\n",
    "        gamma2 = eigvecs[0, :]**2\n",
    "\n",
    "        # Sum of gamma2 * log(theta)\n",
    "        count = torch.sum(gamma2 * torch.log(theta))\n",
    "        z1[ii] = count * n\n",
    "\n",
    "    return z1.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:01.678135800Z",
     "start_time": "2024-07-25T03:59:01.645013800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28772\\AppData\\Local\\Temp\\ipykernel_28952\\1398026063.py:55: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:301.)\n",
      "  z1[ii] = count * n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lanczos Quadrature Time: 0.694256 seconds\n",
      "Log determinant (SLQ): -7871.504354895441\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "log_det_lanc = lanc_quad_logdet(Sigma)\n",
    "end_time = time.time()\n",
    "print(f\"Lanczos Quadrature Time: {end_time - start_time:.6f} seconds\")\n",
    "print(f\"Log determinant (SLQ): {log_det_lanc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:04.303917900Z",
     "start_time": "2024-07-25T03:59:03.571791300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky Decomposition Time: 0.027397 seconds\n",
      "Exact log determinant (Cholesky): -7861.8012705561905\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "L = torch.linalg.cholesky(Sigma)\n",
    "log_det_cholesky=2 * torch.sum(torch.log(torch.diag(L)))\n",
    "end_time = time.time()\n",
    "print(f\"Cholesky Decomposition Time: {end_time - start_time:.6f} seconds\")\n",
    "print(f\"Exact log determinant (Cholesky): {log_det_cholesky.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:04.308925700Z",
     "start_time": "2024-07-25T03:59:04.271420900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again the difference is acceptable. Now we can build our standard GP with new inference methods that leverage GPU acceleration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def negative_log_likelihood(xtr, ytr, kernel,log_beta):\n",
    "    n = xtr.shape[0]\n",
    "    Sigma = kernel(xtr, xtr) + torch.eye(n, device=device) * torch.exp(log_beta) + JITTER * torch.eye(n, device=device)\n",
    "    print(kernel(xtr, xtr) )\n",
    "    Sigma_inv_y = conjugate_gradient(Sigma, ytr)\n",
    "    #option1:\n",
    "    L=torch.linalg.cholesky(Sigma)\n",
    "    nll = 0.5 * (torch.matmul(ytr.t(), Sigma_inv_y) + 0.5* n * torch.log(2 * torch.tensor(PI))) +L.diag().log().sum()\n",
    "    #option2:\n",
    "    #nll=0.5 * (torch.matmul(ytr.t(), Sigma_inv_y) + 0.5* n * torch.log(2 * torch.tensor(PI)))+0.5*lanc_quad_logdet(Sigma)\n",
    "    return nll\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:13.226524700Z",
     "start_time": "2024-07-25T03:59:13.214458100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def forward(xtr, ytr, xte, kernel,log_beta):\n",
    "    n_test = xte.size(0)\n",
    "    #xte=data_normalizer.normalize(xte)\n",
    "    Sigma = kernel(xtr, xtr) + torch.eye(xtr.size(0), device=device) * torch.exp(log_beta) + JITTER * torch.eye(xtr.size(0), device=device)\n",
    "\n",
    "    K_s = kernel(xtr, xte)\n",
    "\n",
    "    mean=K_s.t()@conjugate_gradient(Sigma, ytr)\n",
    "\n",
    "    #option 1 (standard):\n",
    "    #K_ss= kernel(xte, xte)\n",
    "    #var_diag=K_ss.diag().view(-1,1)-  K_s.t()@conjugate_gradient(Sigma, K_s).sum(dim = 0).view(-1, 1)\n",
    "\n",
    "    #option 2 (fast):\n",
    "    var_diag = kernel.signal_variance.exp().expand(n_test, 1).to(device) -  (K_s.t()@conjugate_gradient(Sigma, K_s)).sum(dim = 0).view(-1, 1)\n",
    "    # The first term of above equation might be different if you use a different kernel!\n",
    "\n",
    "    var_diag = var_diag + log_beta.exp().pow(-1)\n",
    "\n",
    "    # Denormalize\n",
    "    #mean, var_diag = data_normalizer.denormalize_result(mean, var_diag)\n",
    "    return mean, var_diag"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:13.612366100Z",
     "start_time": "2024-07-25T03:59:13.604390400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def train_adam(xtr, ytr, kernel, log_beta, niteration=10, lr=0.1):\n",
    "    # Adam optimizer\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': kernel.parameters()},\n",
    "        {'params': [log_beta]}\n",
    "    ], lr=lr)\n",
    "\n",
    "    for i in range(niteration):\n",
    "        optimizer.zero_grad()\n",
    "        loss = negative_log_likelihood(xtr, ytr, kernel, log_beta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print kernel parameters\n",
    "        for name, param in kernel.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'{name}: {param.data}')\n",
    "\n",
    "        #print('log_beta:', log_beta.data)\n",
    "\n",
    "        print('iter', i, 'nll:{:.5f}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:14.170110500Z",
     "start_time": "2024-07-25T03:59:14.160833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7183, 2.7183, 2.7125,  ..., 2.6802, 1.9898, 1.8764],\n",
      "        [2.7183, 2.7183, 2.7133,  ..., 2.6824, 1.9972, 1.8841],\n",
      "        [2.7125, 2.7133, 2.7183,  ..., 2.7041, 2.0908, 1.9809],\n",
      "        ...,\n",
      "        [2.6802, 2.6824, 2.7041,  ..., 2.7183, 2.2401, 2.1378],\n",
      "        [1.9898, 1.9972, 2.0908,  ..., 2.2401, 2.7183, 2.7114],\n",
      "        [1.8764, 1.8841, 1.9809,  ..., 2.1378, 2.7114, 2.7183]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-1.0000e-04], dtype=torch.float64)\n",
      "signal_variance: tensor([1.0000e-04])\n",
      "iter 0 nll:370556.24201\n",
      "tensor([[2.7186, 2.7185, 2.7127,  ..., 2.6805, 1.9898, 1.8764],\n",
      "        [2.7185, 2.7186, 2.7136,  ..., 2.6826, 1.9973, 1.8841],\n",
      "        [2.7127, 2.7136, 2.7186,  ..., 2.7043, 2.0909, 1.9810],\n",
      "        ...,\n",
      "        [2.6805, 2.6826, 2.7043,  ..., 2.7186, 2.2403, 2.1380],\n",
      "        [1.9898, 1.9973, 2.0909,  ..., 2.2403, 2.7186, 2.7117],\n",
      "        [1.8764, 1.8841, 1.9810,  ..., 2.1380, 2.7117, 2.7186]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0002], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0002])\n",
      "iter 1 nll:370479.24218\n",
      "tensor([[2.7188, 2.7188, 2.7130,  ..., 2.6808, 1.9899, 1.8765],\n",
      "        [2.7188, 2.7188, 2.7138,  ..., 2.6829, 1.9974, 1.8842],\n",
      "        [2.7130, 2.7138, 2.7188,  ..., 2.7046, 2.0910, 1.9810],\n",
      "        ...,\n",
      "        [2.6808, 2.6829, 2.7046,  ..., 2.7188, 2.2404, 2.1381],\n",
      "        [1.9899, 1.9974, 2.0910,  ..., 2.2404, 2.7188, 2.7120],\n",
      "        [1.8765, 1.8842, 1.9810,  ..., 2.1381, 2.7120, 2.7188]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0003], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0003])\n",
      "iter 2 nll:370402.24443\n",
      "tensor([[2.7191, 2.7191, 2.7133,  ..., 2.6810, 1.9900, 1.8765],\n",
      "        [2.7191, 2.7191, 2.7141,  ..., 2.6831, 1.9975, 1.8842],\n",
      "        [2.7133, 2.7141, 2.7191,  ..., 2.7049, 2.0911, 1.9811],\n",
      "        ...,\n",
      "        [2.6810, 2.6831, 2.7049,  ..., 2.7191, 2.2405, 2.1382],\n",
      "        [1.9900, 1.9975, 2.0911,  ..., 2.2405, 2.7191, 2.7122],\n",
      "        [1.8765, 1.8842, 1.9811,  ..., 2.1382, 2.7122, 2.7191]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0004], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0004])\n",
      "iter 3 nll:370325.25176\n",
      "tensor([[2.7194, 2.7193, 2.7136,  ..., 2.6813, 1.9901, 1.8766],\n",
      "        [2.7193, 2.7194, 2.7144,  ..., 2.6834, 1.9975, 1.8843],\n",
      "        [2.7136, 2.7144, 2.7194,  ..., 2.7051, 2.0912, 1.9812],\n",
      "        ...,\n",
      "        [2.6813, 2.6834, 2.7051,  ..., 2.7194, 2.2407, 2.1383],\n",
      "        [1.9901, 1.9975, 2.0912,  ..., 2.2407, 2.7194, 2.7125],\n",
      "        [1.8766, 1.8843, 1.9812,  ..., 2.1383, 2.7125, 2.7194]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0005], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0005])\n",
      "iter 4 nll:370248.25464\n",
      "tensor([[2.7196, 2.7196, 2.7138,  ..., 2.6816, 1.9901, 1.8766],\n",
      "        [2.7196, 2.7196, 2.7146,  ..., 2.6837, 1.9976, 1.8843],\n",
      "        [2.7138, 2.7146, 2.7196,  ..., 2.7054, 2.0913, 1.9813],\n",
      "        ...,\n",
      "        [2.6816, 2.6837, 2.7054,  ..., 2.7196, 2.2408, 2.1384],\n",
      "        [1.9901, 1.9976, 2.0913,  ..., 2.2408, 2.7196, 2.7128],\n",
      "        [1.8766, 1.8843, 1.9813,  ..., 2.1384, 2.7128, 2.7196]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0006], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0006])\n",
      "iter 5 nll:370171.26717\n",
      "tensor([[2.7199, 2.7199, 2.7141,  ..., 2.6818, 1.9902, 1.8767],\n",
      "        [2.7199, 2.7199, 2.7149,  ..., 2.6839, 1.9977, 1.8844],\n",
      "        [2.7141, 2.7149, 2.7199,  ..., 2.7057, 2.0914, 1.9813],\n",
      "        ...,\n",
      "        [2.6818, 2.6839, 2.7057,  ..., 2.7199, 2.2409, 2.1385],\n",
      "        [1.9902, 1.9977, 2.0914,  ..., 2.2409, 2.7199, 2.7130],\n",
      "        [1.8767, 1.8844, 1.9813,  ..., 2.1385, 2.7130, 2.7199]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0007], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0007])\n",
      "iter 6 nll:370094.25563\n",
      "tensor([[2.7202, 2.7202, 2.7144,  ..., 2.6821, 1.9903, 1.8767],\n",
      "        [2.7202, 2.7202, 2.7152,  ..., 2.6842, 1.9978, 1.8844],\n",
      "        [2.7144, 2.7152, 2.7202,  ..., 2.7059, 2.0915, 1.9814],\n",
      "        ...,\n",
      "        [2.6821, 2.6842, 2.7059,  ..., 2.7202, 2.2411, 2.1386],\n",
      "        [1.9903, 1.9978, 2.0915,  ..., 2.2411, 2.7202, 2.7133],\n",
      "        [1.8767, 1.8844, 1.9814,  ..., 2.1386, 2.7133, 2.7202]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0008], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0008])\n",
      "iter 7 nll:370017.27207\n",
      "tensor([[2.7205, 2.7204, 2.7146,  ..., 2.6823, 1.9904, 1.8768],\n",
      "        [2.7204, 2.7205, 2.7154,  ..., 2.6844, 1.9978, 1.8845],\n",
      "        [2.7146, 2.7154, 2.7205,  ..., 2.7062, 2.0916, 1.9815],\n",
      "        ...,\n",
      "        [2.6823, 2.6844, 2.7062,  ..., 2.7205, 2.2412, 2.1387],\n",
      "        [1.9904, 1.9978, 2.0916,  ..., 2.2412, 2.7205, 2.7136],\n",
      "        [1.8768, 1.8845, 1.9815,  ..., 2.1387, 2.7136, 2.7205]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0009], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0009])\n",
      "iter 8 nll:369940.26723\n",
      "tensor([[2.7207, 2.7207, 2.7149,  ..., 2.6826, 1.9904, 1.8768],\n",
      "        [2.7207, 2.7207, 2.7157,  ..., 2.6847, 1.9979, 1.8845],\n",
      "        [2.7149, 2.7157, 2.7207,  ..., 2.7065, 2.0917, 1.9815],\n",
      "        ...,\n",
      "        [2.6826, 2.6847, 2.7065,  ..., 2.7207, 2.2414, 2.1388],\n",
      "        [1.9904, 1.9979, 2.0917,  ..., 2.2414, 2.7207, 2.7139],\n",
      "        [1.8768, 1.8845, 1.9815,  ..., 2.1388, 2.7139, 2.7207]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0010], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0010])\n",
      "iter 9 nll:369863.26612\n",
      "tensor([[2.7210, 2.7210, 2.7152,  ..., 2.6829, 1.9905, 1.8769],\n",
      "        [2.7210, 2.7210, 2.7160,  ..., 2.6850, 1.9980, 1.8846],\n",
      "        [2.7152, 2.7160, 2.7210,  ..., 2.7067, 2.0918, 1.9816],\n",
      "        ...,\n",
      "        [2.6829, 2.6850, 2.7067,  ..., 2.7210, 2.2415, 2.1390],\n",
      "        [1.9905, 1.9980, 2.0918,  ..., 2.2415, 2.7210, 2.7141],\n",
      "        [1.8769, 1.8846, 1.9816,  ..., 2.1390, 2.7141, 2.7210]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0011], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0011])\n",
      "iter 10 nll:369786.27159\n",
      "tensor([[2.7213, 2.7212, 2.7154,  ..., 2.6831, 1.9906, 1.8769],\n",
      "        [2.7212, 2.7213, 2.7163,  ..., 2.6852, 1.9981, 1.8846],\n",
      "        [2.7154, 2.7163, 2.7213,  ..., 2.7070, 2.0919, 1.9817],\n",
      "        ...,\n",
      "        [2.6831, 2.6852, 2.7070,  ..., 2.7213, 2.2416, 2.1391],\n",
      "        [1.9906, 1.9981, 2.0919,  ..., 2.2416, 2.7213, 2.7144],\n",
      "        [1.8769, 1.8846, 1.9817,  ..., 2.1391, 2.7144, 2.7213]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0012], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0012])\n",
      "iter 11 nll:369709.26645\n",
      "tensor([[2.7215, 2.7215, 2.7157,  ..., 2.6834, 1.9907, 1.8770],\n",
      "        [2.7215, 2.7215, 2.7165,  ..., 2.6855, 1.9981, 1.8847],\n",
      "        [2.7157, 2.7165, 2.7215,  ..., 2.7073, 2.0920, 1.9818],\n",
      "        ...,\n",
      "        [2.6834, 2.6855, 2.7073,  ..., 2.7215, 2.2418, 2.1392],\n",
      "        [1.9907, 1.9981, 2.0920,  ..., 2.2418, 2.7215, 2.7147],\n",
      "        [1.8770, 1.8847, 1.9818,  ..., 2.1392, 2.7147, 2.7215]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0013], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0013])\n",
      "iter 12 nll:369632.26937\n",
      "tensor([[2.7218, 2.7218, 2.7160,  ..., 2.6836, 1.9907, 1.8770],\n",
      "        [2.7218, 2.7218, 2.7168,  ..., 2.6858, 1.9982, 1.8847],\n",
      "        [2.7160, 2.7168, 2.7218,  ..., 2.7075, 2.0921, 1.9818],\n",
      "        ...,\n",
      "        [2.6836, 2.6858, 2.7075,  ..., 2.7218, 2.2419, 2.1393],\n",
      "        [1.9907, 1.9982, 2.0921,  ..., 2.2419, 2.7218, 2.7149],\n",
      "        [1.8770, 1.8847, 1.9818,  ..., 2.1393, 2.7149, 2.7218]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0014], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0014])\n",
      "iter 13 nll:369555.27483\n",
      "tensor([[2.7221, 2.7221, 2.7163,  ..., 2.6839, 1.9908, 1.8771],\n",
      "        [2.7221, 2.7221, 2.7171,  ..., 2.6860, 1.9983, 1.8848],\n",
      "        [2.7163, 2.7171, 2.7221,  ..., 2.7078, 2.0922, 1.9819],\n",
      "        ...,\n",
      "        [2.6839, 2.6860, 2.7078,  ..., 2.7221, 2.2420, 2.1394],\n",
      "        [1.9908, 1.9983, 2.0922,  ..., 2.2420, 2.7221, 2.7152],\n",
      "        [1.8771, 1.8848, 1.9819,  ..., 2.1394, 2.7152, 2.7221]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0015], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0015])\n",
      "iter 14 nll:369478.25599\n",
      "tensor([[2.7224, 2.7223, 2.7165,  ..., 2.6842, 1.9909, 1.8771],\n",
      "        [2.7223, 2.7224, 2.7173,  ..., 2.6863, 1.9984, 1.8848],\n",
      "        [2.7165, 2.7173, 2.7224,  ..., 2.7081, 2.0923, 1.9820],\n",
      "        ...,\n",
      "        [2.6842, 2.6863, 2.7081,  ..., 2.7224, 2.2422, 2.1395],\n",
      "        [1.9909, 1.9984, 2.0923,  ..., 2.2422, 2.7224, 2.7155],\n",
      "        [1.8771, 1.8848, 1.9820,  ..., 2.1395, 2.7155, 2.7224]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0016], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0016])\n",
      "iter 15 nll:369401.26121\n",
      "tensor([[2.7226, 2.7226, 2.7168,  ..., 2.6844, 1.9910, 1.8772],\n",
      "        [2.7226, 2.7226, 2.7176,  ..., 2.6865, 1.9985, 1.8849],\n",
      "        [2.7168, 2.7176, 2.7226,  ..., 2.7083, 2.0924, 1.9821],\n",
      "        ...,\n",
      "        [2.6844, 2.6865, 2.7083,  ..., 2.7226, 2.2423, 2.1396],\n",
      "        [1.9910, 1.9985, 2.0924,  ..., 2.2423, 2.7226, 2.7157],\n",
      "        [1.8772, 1.8849, 1.9821,  ..., 2.1396, 2.7157, 2.7226]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0017], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0017])\n",
      "iter 16 nll:369324.25830\n",
      "tensor([[2.7229, 2.7229, 2.7171,  ..., 2.6847, 1.9910, 1.8772],\n",
      "        [2.7229, 2.7229, 2.7179,  ..., 2.6868, 1.9985, 1.8849],\n",
      "        [2.7171, 2.7179, 2.7229,  ..., 2.7086, 2.0925, 1.9821],\n",
      "        ...,\n",
      "        [2.6847, 2.6868, 2.7086,  ..., 2.7229, 2.2425, 2.1397],\n",
      "        [1.9910, 1.9985, 2.0925,  ..., 2.2425, 2.7229, 2.7160],\n",
      "        [1.8772, 1.8849, 1.9821,  ..., 2.1397, 2.7160, 2.7229]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0018], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0018])\n",
      "iter 17 nll:369247.25554\n",
      "tensor([[2.7232, 2.7232, 2.7173,  ..., 2.6849, 1.9911, 1.8773],\n",
      "        [2.7232, 2.7232, 2.7182,  ..., 2.6871, 1.9986, 1.8850],\n",
      "        [2.7173, 2.7182, 2.7232,  ..., 2.7089, 2.0926, 1.9822],\n",
      "        ...,\n",
      "        [2.6849, 2.6871, 2.7089,  ..., 2.7232, 2.2426, 2.1398],\n",
      "        [1.9911, 1.9986, 2.0926,  ..., 2.2426, 2.7232, 2.7163],\n",
      "        [1.8773, 1.8850, 1.9822,  ..., 2.1398, 2.7163, 2.7232]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0019], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0019])\n",
      "iter 18 nll:369170.24646\n",
      "tensor([[2.7235, 2.7234, 2.7176,  ..., 2.6852, 1.9912, 1.8773],\n",
      "        [2.7234, 2.7235, 2.7184,  ..., 2.6873, 1.9987, 1.8850],\n",
      "        [2.7176, 2.7184, 2.7235,  ..., 2.7092, 2.0927, 1.9823],\n",
      "        ...,\n",
      "        [2.6852, 2.6873, 2.7092,  ..., 2.7235, 2.2427, 2.1400],\n",
      "        [1.9912, 1.9987, 2.0927,  ..., 2.2427, 2.7235, 2.7166],\n",
      "        [1.8773, 1.8850, 1.9823,  ..., 2.1400, 2.7166, 2.7235]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0020], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0020])\n",
      "iter 19 nll:369093.24120\n",
      "tensor([[2.7237, 2.7237, 2.7179,  ..., 2.6855, 1.9913, 1.8774],\n",
      "        [2.7237, 2.7237, 2.7187,  ..., 2.6876, 1.9988, 1.8851],\n",
      "        [2.7179, 2.7187, 2.7237,  ..., 2.7094, 2.0928, 1.9823],\n",
      "        ...,\n",
      "        [2.6855, 2.6876, 2.7094,  ..., 2.7237, 2.2429, 2.1401],\n",
      "        [1.9913, 1.9988, 2.0928,  ..., 2.2429, 2.7237, 2.7168],\n",
      "        [1.8774, 1.8851, 1.9823,  ..., 2.1401, 2.7168, 2.7237]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0021], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0021])\n",
      "iter 20 nll:369016.24204\n",
      "tensor([[2.7240, 2.7240, 2.7182,  ..., 2.6857, 1.9913, 1.8774],\n",
      "        [2.7240, 2.7240, 2.7190,  ..., 2.6879, 1.9988, 1.8851],\n",
      "        [2.7182, 2.7190, 2.7240,  ..., 2.7097, 2.0929, 1.9824],\n",
      "        ...,\n",
      "        [2.6857, 2.6879, 2.7097,  ..., 2.7240, 2.2430, 2.1402],\n",
      "        [1.9913, 1.9988, 2.0929,  ..., 2.2430, 2.7240, 2.7171],\n",
      "        [1.8774, 1.8851, 1.9824,  ..., 2.1402, 2.7171, 2.7240]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0022], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0022])\n",
      "iter 21 nll:368939.23303\n",
      "tensor([[2.7243, 2.7242, 2.7184,  ..., 2.6860, 1.9914, 1.8775],\n",
      "        [2.7242, 2.7243, 2.7192,  ..., 2.6881, 1.9989, 1.8852],\n",
      "        [2.7184, 2.7192, 2.7243,  ..., 2.7100, 2.0930, 1.9825],\n",
      "        ...,\n",
      "        [2.6860, 2.6881, 2.7100,  ..., 2.7243, 2.2431, 2.1403],\n",
      "        [1.9914, 1.9989, 2.0930,  ..., 2.2431, 2.7243, 2.7174],\n",
      "        [1.8775, 1.8852, 1.9825,  ..., 2.1403, 2.7174, 2.7243]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0023], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0023])\n",
      "iter 22 nll:368862.23214\n",
      "tensor([[2.7246, 2.7245, 2.7187,  ..., 2.6863, 1.9915, 1.8775],\n",
      "        [2.7245, 2.7246, 2.7195,  ..., 2.6884, 1.9990, 1.8852],\n",
      "        [2.7187, 2.7195, 2.7246,  ..., 2.7102, 2.0931, 1.9826],\n",
      "        ...,\n",
      "        [2.6863, 2.6884, 2.7102,  ..., 2.7246, 2.2433, 2.1404],\n",
      "        [1.9915, 1.9990, 2.0931,  ..., 2.2433, 2.7246, 2.7176],\n",
      "        [1.8775, 1.8852, 1.9826,  ..., 2.1404, 2.7176, 2.7246]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0024], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0024])\n",
      "iter 23 nll:368785.21702\n",
      "tensor([[2.7248, 2.7248, 2.7190,  ..., 2.6865, 1.9916, 1.8776],\n",
      "        [2.7248, 2.7248, 2.7198,  ..., 2.6886, 1.9991, 1.8853],\n",
      "        [2.7190, 2.7198, 2.7248,  ..., 2.7105, 2.0932, 1.9826],\n",
      "        ...,\n",
      "        [2.6865, 2.6886, 2.7105,  ..., 2.7248, 2.2434, 2.1405],\n",
      "        [1.9916, 1.9991, 2.0932,  ..., 2.2434, 2.7248, 2.7179],\n",
      "        [1.8776, 1.8853, 1.9826,  ..., 2.1405, 2.7179, 2.7248]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0025], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0025])\n",
      "iter 24 nll:368708.22120\n",
      "tensor([[2.7251, 2.7251, 2.7192,  ..., 2.6868, 1.9916, 1.8776],\n",
      "        [2.7251, 2.7251, 2.7201,  ..., 2.6889, 1.9991, 1.8853],\n",
      "        [2.7192, 2.7201, 2.7251,  ..., 2.7108, 2.0933, 1.9827],\n",
      "        ...,\n",
      "        [2.6868, 2.6889, 2.7108,  ..., 2.7251, 2.2436, 2.1406],\n",
      "        [1.9916, 1.9991, 2.0933,  ..., 2.2436, 2.7251, 2.7182],\n",
      "        [1.8776, 1.8853, 1.9827,  ..., 2.1406, 2.7182, 2.7251]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0026], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0026])\n",
      "iter 25 nll:368631.20868\n",
      "tensor([[2.7254, 2.7253, 2.7195,  ..., 2.6870, 1.9917, 1.8777],\n",
      "        [2.7253, 2.7254, 2.7203,  ..., 2.6892, 1.9992, 1.8854],\n",
      "        [2.7195, 2.7203, 2.7254,  ..., 2.7110, 2.0934, 1.9828],\n",
      "        ...,\n",
      "        [2.6870, 2.6892, 2.7110,  ..., 2.7254, 2.2437, 2.1407],\n",
      "        [1.9917, 1.9992, 2.0934,  ..., 2.2437, 2.7254, 2.7185],\n",
      "        [1.8777, 1.8854, 1.9828,  ..., 2.1407, 2.7185, 2.7254]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0027], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0027])\n",
      "iter 26 nll:368554.19617\n",
      "tensor([[2.7256, 2.7256, 2.7198,  ..., 2.6873, 1.9918, 1.8777],\n",
      "        [2.7256, 2.7256, 2.7206,  ..., 2.6894, 1.9993, 1.8854],\n",
      "        [2.7198, 2.7206, 2.7256,  ..., 2.7113, 2.0935, 1.9829],\n",
      "        ...,\n",
      "        [2.6873, 2.6894, 2.7113,  ..., 2.7256, 2.2438, 2.1408],\n",
      "        [1.9918, 1.9993, 2.0935,  ..., 2.2438, 2.7256, 2.7187],\n",
      "        [1.8777, 1.8854, 1.9829,  ..., 2.1408, 2.7187, 2.7256]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0028], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0028])\n",
      "iter 27 nll:368477.18938\n",
      "tensor([[2.7259, 2.7259, 2.7201,  ..., 2.6876, 1.9919, 1.8777],\n",
      "        [2.7259, 2.7259, 2.7209,  ..., 2.6897, 1.9994, 1.8855],\n",
      "        [2.7201, 2.7209, 2.7259,  ..., 2.7116, 2.0936, 1.9829],\n",
      "        ...,\n",
      "        [2.6876, 2.6897, 2.7116,  ..., 2.7259, 2.2440, 2.1410],\n",
      "        [1.9919, 1.9994, 2.0936,  ..., 2.2440, 2.7259, 2.7190],\n",
      "        [1.8777, 1.8855, 1.9829,  ..., 2.1410, 2.7190, 2.7259]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0029], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0029])\n",
      "iter 28 nll:368400.18354\n",
      "tensor([[2.7262, 2.7262, 2.7203,  ..., 2.6878, 1.9919, 1.8778],\n",
      "        [2.7262, 2.7262, 2.7211,  ..., 2.6900, 1.9994, 1.8855],\n",
      "        [2.7203, 2.7211, 2.7262,  ..., 2.7118, 2.0937, 1.9830],\n",
      "        ...,\n",
      "        [2.6878, 2.6900, 2.7118,  ..., 2.7262, 2.2441, 2.1411],\n",
      "        [1.9919, 1.9994, 2.0937,  ..., 2.2441, 2.7262, 2.7193],\n",
      "        [1.8778, 1.8855, 1.9830,  ..., 2.1411, 2.7193, 2.7262]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0030], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0030])\n",
      "iter 29 nll:368323.16593\n",
      "tensor([[2.7265, 2.7264, 2.7206,  ..., 2.6881, 1.9920, 1.8778],\n",
      "        [2.7264, 2.7265, 2.7214,  ..., 2.6902, 1.9995, 1.8856],\n",
      "        [2.7206, 2.7214, 2.7265,  ..., 2.7121, 2.0938, 1.9831],\n",
      "        ...,\n",
      "        [2.6881, 2.6902, 2.7121,  ..., 2.7265, 2.2442, 2.1412],\n",
      "        [1.9920, 1.9995, 2.0938,  ..., 2.2442, 2.7265, 2.7195],\n",
      "        [1.8778, 1.8856, 1.9831,  ..., 2.1412, 2.7195, 2.7265]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0031], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0031])\n",
      "iter 30 nll:368246.15254\n",
      "tensor([[2.7267, 2.7267, 2.7209,  ..., 2.6884, 1.9921, 1.8779],\n",
      "        [2.7267, 2.7267, 2.7217,  ..., 2.6905, 1.9996, 1.8856],\n",
      "        [2.7209, 2.7217, 2.7267,  ..., 2.7124, 2.0939, 1.9831],\n",
      "        ...,\n",
      "        [2.6884, 2.6905, 2.7124,  ..., 2.7267, 2.2444, 2.1413],\n",
      "        [1.9921, 1.9996, 2.0939,  ..., 2.2444, 2.7267, 2.7198],\n",
      "        [1.8779, 1.8856, 1.9831,  ..., 2.1413, 2.7198, 2.7267]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0032], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0032])\n",
      "iter 31 nll:368169.13726\n",
      "tensor([[2.7270, 2.7270, 2.7211,  ..., 2.6886, 1.9922, 1.8779],\n",
      "        [2.7270, 2.7270, 2.7220,  ..., 2.6907, 1.9997, 1.8857],\n",
      "        [2.7211, 2.7220, 2.7270,  ..., 2.7127, 2.0940, 1.9832],\n",
      "        ...,\n",
      "        [2.6886, 2.6907, 2.7127,  ..., 2.7270, 2.2445, 2.1414],\n",
      "        [1.9922, 1.9997, 2.0940,  ..., 2.2445, 2.7270, 2.7201],\n",
      "        [1.8779, 1.8857, 1.9832,  ..., 2.1414, 2.7201, 2.7270]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0033], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0033])\n",
      "iter 32 nll:368092.12720\n",
      "tensor([[2.7273, 2.7273, 2.7214,  ..., 2.6889, 1.9922, 1.8780],\n",
      "        [2.7273, 2.7273, 2.7222,  ..., 2.6910, 1.9998, 1.8857],\n",
      "        [2.7214, 2.7222, 2.7273,  ..., 2.7129, 2.0941, 1.9833],\n",
      "        ...,\n",
      "        [2.6889, 2.6910, 2.7129,  ..., 2.7273, 2.2447, 2.1415],\n",
      "        [1.9922, 1.9998, 2.0941,  ..., 2.2447, 2.7273, 2.7204],\n",
      "        [1.8780, 1.8857, 1.9833,  ..., 2.1415, 2.7204, 2.7273]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0034], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0034])\n",
      "iter 33 nll:368015.12036\n",
      "tensor([[2.7276, 2.7275, 2.7217,  ..., 2.6891, 1.9923, 1.8780],\n",
      "        [2.7275, 2.7276, 2.7225,  ..., 2.6913, 1.9998, 1.8858],\n",
      "        [2.7217, 2.7225, 2.7276,  ..., 2.7132, 2.0942, 1.9834],\n",
      "        ...,\n",
      "        [2.6891, 2.6913, 2.7132,  ..., 2.7276, 2.2448, 2.1416],\n",
      "        [1.9923, 1.9998, 2.0942,  ..., 2.2448, 2.7276, 2.7206],\n",
      "        [1.8780, 1.8858, 1.9834,  ..., 2.1416, 2.7206, 2.7276]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0035], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0035])\n",
      "iter 34 nll:367938.10957\n",
      "tensor([[2.7278, 2.7278, 2.7220,  ..., 2.6894, 1.9924, 1.8781],\n",
      "        [2.7278, 2.7278, 2.7228,  ..., 2.6915, 1.9999, 1.8858],\n",
      "        [2.7220, 2.7228, 2.7278,  ..., 2.7135, 2.0943, 1.9834],\n",
      "        ...,\n",
      "        [2.6894, 2.6915, 2.7135,  ..., 2.7278, 2.2449, 2.1417],\n",
      "        [1.9924, 1.9999, 2.0943,  ..., 2.2449, 2.7278, 2.7209],\n",
      "        [1.8781, 1.8858, 1.9834,  ..., 2.1417, 2.7209, 2.7278]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0036], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0036])\n",
      "iter 35 nll:367861.08501\n",
      "tensor([[2.7281, 2.7281, 2.7222,  ..., 2.6897, 1.9925, 1.8781],\n",
      "        [2.7281, 2.7281, 2.7231,  ..., 2.6918, 2.0000, 1.8859],\n",
      "        [2.7222, 2.7231, 2.7281,  ..., 2.7137, 2.0944, 1.9835],\n",
      "        ...,\n",
      "        [2.6897, 2.6918, 2.7137,  ..., 2.7281, 2.2451, 2.1418],\n",
      "        [1.9925, 2.0000, 2.0944,  ..., 2.2451, 2.7281, 2.7212],\n",
      "        [1.8781, 1.8859, 1.9835,  ..., 2.1418, 2.7212, 2.7281]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0037], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0037])\n",
      "iter 36 nll:367784.06566\n",
      "tensor([[2.7284, 2.7284, 2.7225,  ..., 2.6899, 1.9925, 1.8782],\n",
      "        [2.7284, 2.7284, 2.7233,  ..., 2.6921, 2.0001, 1.8859],\n",
      "        [2.7225, 2.7233, 2.7284,  ..., 2.7140, 2.0945, 1.9836],\n",
      "        ...,\n",
      "        [2.6899, 2.6921, 2.7140,  ..., 2.7284, 2.2452, 2.1420],\n",
      "        [1.9925, 2.0001, 2.0945,  ..., 2.2452, 2.7284, 2.7215],\n",
      "        [1.8782, 1.8859, 1.9836,  ..., 2.1420, 2.7215, 2.7284]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0038], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0038])\n",
      "iter 37 nll:367707.06200\n",
      "tensor([[2.7287, 2.7286, 2.7228,  ..., 2.6902, 1.9926, 1.8782],\n",
      "        [2.7286, 2.7287, 2.7236,  ..., 2.6923, 2.0001, 1.8860],\n",
      "        [2.7228, 2.7236, 2.7287,  ..., 2.7143, 2.0946, 1.9837],\n",
      "        ...,\n",
      "        [2.6902, 2.6923, 2.7143,  ..., 2.7287, 2.2454, 2.1421],\n",
      "        [1.9926, 2.0001, 2.0946,  ..., 2.2454, 2.7287, 2.7217],\n",
      "        [1.8782, 1.8860, 1.9837,  ..., 2.1421, 2.7217, 2.7287]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0039], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0039])\n",
      "iter 38 nll:367630.03464\n",
      "tensor([[2.7289, 2.7289, 2.7231,  ..., 2.6905, 1.9927, 1.8783],\n",
      "        [2.7289, 2.7289, 2.7239,  ..., 2.6926, 2.0002, 1.8860],\n",
      "        [2.7231, 2.7239, 2.7289,  ..., 2.7145, 2.0947, 1.9837],\n",
      "        ...,\n",
      "        [2.6905, 2.6926, 2.7145,  ..., 2.7289, 2.2455, 2.1422],\n",
      "        [1.9927, 2.0002, 2.0947,  ..., 2.2455, 2.7289, 2.7220],\n",
      "        [1.8783, 1.8860, 1.9837,  ..., 2.1422, 2.7220, 2.7289]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0040], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0040])\n",
      "iter 39 nll:367553.01781\n",
      "tensor([[2.7292, 2.7292, 2.7233,  ..., 2.6907, 1.9928, 1.8783],\n",
      "        [2.7292, 2.7292, 2.7241,  ..., 2.6929, 2.0003, 1.8861],\n",
      "        [2.7233, 2.7241, 2.7292,  ..., 2.7148, 2.0948, 1.9838],\n",
      "        ...,\n",
      "        [2.6907, 2.6929, 2.7148,  ..., 2.7292, 2.2456, 2.1423],\n",
      "        [1.9928, 2.0003, 2.0948,  ..., 2.2456, 2.7292, 2.7223],\n",
      "        [1.8783, 1.8861, 1.9838,  ..., 2.1423, 2.7223, 2.7292]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0041], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0041])\n",
      "iter 40 nll:367475.99640\n",
      "tensor([[2.7295, 2.7295, 2.7236,  ..., 2.6910, 1.9928, 1.8784],\n",
      "        [2.7295, 2.7295, 2.7244,  ..., 2.6931, 2.0004, 1.8861],\n",
      "        [2.7236, 2.7244, 2.7295,  ..., 2.7151, 2.0949, 1.9839],\n",
      "        ...,\n",
      "        [2.6910, 2.6931, 2.7151,  ..., 2.7295, 2.2458, 2.1424],\n",
      "        [1.9928, 2.0004, 2.0949,  ..., 2.2458, 2.7295, 2.7225],\n",
      "        [1.8784, 1.8861, 1.9839,  ..., 2.1424, 2.7225, 2.7295]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0042], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0042])\n",
      "iter 41 nll:367398.98032\n",
      "tensor([[2.7298, 2.7297, 2.7239,  ..., 2.6912, 1.9929, 1.8784],\n",
      "        [2.7297, 2.7298, 2.7247,  ..., 2.6934, 2.0004, 1.8862],\n",
      "        [2.7239, 2.7247, 2.7298,  ..., 2.7154, 2.0950, 1.9839],\n",
      "        ...,\n",
      "        [2.6912, 2.6934, 2.7154,  ..., 2.7298, 2.2459, 2.1425],\n",
      "        [1.9929, 2.0004, 2.0950,  ..., 2.2459, 2.7298, 2.7228],\n",
      "        [1.8784, 1.8862, 1.9839,  ..., 2.1425, 2.7228, 2.7298]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0043], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0043])\n",
      "iter 42 nll:367321.96230\n",
      "tensor([[2.7300, 2.7300, 2.7241,  ..., 2.6915, 1.9930, 1.8785],\n",
      "        [2.7300, 2.7300, 2.7250,  ..., 2.6936, 2.0005, 1.8862],\n",
      "        [2.7241, 2.7250, 2.7300,  ..., 2.7156, 2.0951, 1.9840],\n",
      "        ...,\n",
      "        [2.6915, 2.6936, 2.7156,  ..., 2.7300, 2.2460, 2.1426],\n",
      "        [1.9930, 2.0005, 2.0951,  ..., 2.2460, 2.7300, 2.7231],\n",
      "        [1.8785, 1.8862, 1.9840,  ..., 2.1426, 2.7231, 2.7300]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0044], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0044])\n",
      "iter 43 nll:367244.93478\n",
      "tensor([[2.7303, 2.7303, 2.7244,  ..., 2.6918, 1.9931, 1.8785],\n",
      "        [2.7303, 2.7303, 2.7252,  ..., 2.6939, 2.0006, 1.8863],\n",
      "        [2.7244, 2.7252, 2.7303,  ..., 2.7159, 2.0952, 1.9841],\n",
      "        ...,\n",
      "        [2.6918, 2.6939, 2.7159,  ..., 2.7303, 2.2462, 2.1427],\n",
      "        [1.9931, 2.0006, 2.0952,  ..., 2.2462, 2.7303, 2.7234],\n",
      "        [1.8785, 1.8863, 1.9841,  ..., 2.1427, 2.7234, 2.7303]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0045], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0045])\n",
      "iter 44 nll:367167.89933\n",
      "tensor([[2.7306, 2.7306, 2.7247,  ..., 2.6920, 1.9931, 1.8786],\n",
      "        [2.7306, 2.7306, 2.7255,  ..., 2.6942, 2.0007, 1.8863],\n",
      "        [2.7247, 2.7255, 2.7306,  ..., 2.7162, 2.0953, 1.9842],\n",
      "        ...,\n",
      "        [2.6920, 2.6942, 2.7162,  ..., 2.7306, 2.2463, 2.1429],\n",
      "        [1.9931, 2.0007, 2.0953,  ..., 2.2463, 2.7306, 2.7236],\n",
      "        [1.8786, 1.8863, 1.9842,  ..., 2.1429, 2.7236, 2.7306]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0046], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0046])\n",
      "iter 45 nll:367090.88786\n",
      "tensor([[2.7309, 2.7308, 2.7250,  ..., 2.6923, 1.9932, 1.8786],\n",
      "        [2.7308, 2.7309, 2.7258,  ..., 2.6944, 2.0008, 1.8864],\n",
      "        [2.7250, 2.7258, 2.7309,  ..., 2.7164, 2.0954, 1.9842],\n",
      "        ...,\n",
      "        [2.6923, 2.6944, 2.7164,  ..., 2.7309, 2.2465, 2.1430],\n",
      "        [1.9932, 2.0008, 2.0954,  ..., 2.2465, 2.7309, 2.7239],\n",
      "        [1.8786, 1.8864, 1.9842,  ..., 2.1430, 2.7239, 2.7309]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0047], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0047])\n",
      "iter 46 nll:367013.86869\n",
      "tensor([[2.7311, 2.7311, 2.7252,  ..., 2.6926, 1.9933, 1.8787],\n",
      "        [2.7311, 2.7311, 2.7261,  ..., 2.6947, 2.0008, 1.8864],\n",
      "        [2.7252, 2.7261, 2.7311,  ..., 2.7167, 2.0955, 1.9843],\n",
      "        ...,\n",
      "        [2.6926, 2.6947, 2.7167,  ..., 2.7311, 2.2466, 2.1431],\n",
      "        [1.9933, 2.0008, 2.0955,  ..., 2.2466, 2.7311, 2.7242],\n",
      "        [1.8787, 1.8864, 1.9843,  ..., 2.1431, 2.7242, 2.7311]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0048], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0048])\n",
      "iter 47 nll:366936.83472\n",
      "tensor([[2.7314, 2.7314, 2.7255,  ..., 2.6928, 1.9934, 1.8787],\n",
      "        [2.7314, 2.7314, 2.7263,  ..., 2.6950, 2.0009, 1.8865],\n",
      "        [2.7255, 2.7263, 2.7314,  ..., 2.7170, 2.0956, 1.9844],\n",
      "        ...,\n",
      "        [2.6928, 2.6950, 2.7170,  ..., 2.7314, 2.2467, 2.1432],\n",
      "        [1.9934, 2.0009, 2.0956,  ..., 2.2467, 2.7314, 2.7245],\n",
      "        [1.8787, 1.8865, 1.9844,  ..., 2.1432, 2.7245, 2.7314]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0049], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0049])\n",
      "iter 48 nll:366859.80645\n",
      "tensor([[2.7317, 2.7317, 2.7258,  ..., 2.6931, 1.9934, 1.8788],\n",
      "        [2.7317, 2.7317, 2.7266,  ..., 2.6952, 2.0010, 1.8865],\n",
      "        [2.7258, 2.7266, 2.7317,  ..., 2.7172, 2.0957, 1.9845],\n",
      "        ...,\n",
      "        [2.6931, 2.6952, 2.7172,  ..., 2.7317, 2.2469, 2.1433],\n",
      "        [1.9934, 2.0010, 2.0957,  ..., 2.2469, 2.7317, 2.7247],\n",
      "        [1.8788, 1.8865, 1.9845,  ..., 2.1433, 2.7247, 2.7317]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0050], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0050])\n",
      "iter 49 nll:366782.78734\n",
      "tensor([[2.7320, 2.7319, 2.7261,  ..., 2.6934, 1.9935, 1.8788],\n",
      "        [2.7319, 2.7320, 2.7269,  ..., 2.6955, 2.0011, 1.8866],\n",
      "        [2.7261, 2.7269, 2.7320,  ..., 2.7175, 2.0958, 1.9845],\n",
      "        ...,\n",
      "        [2.6934, 2.6955, 2.7175,  ..., 2.7320, 2.2470, 2.1434],\n",
      "        [1.9935, 2.0011, 2.0958,  ..., 2.2470, 2.7320, 2.7250],\n",
      "        [1.8788, 1.8866, 1.9845,  ..., 2.1434, 2.7250, 2.7320]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0051], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0051])\n",
      "iter 50 nll:366705.75981\n",
      "tensor([[2.7322, 2.7322, 2.7263,  ..., 2.6936, 1.9936, 1.8789],\n",
      "        [2.7322, 2.7322, 2.7272,  ..., 2.6958, 2.0011, 1.8866],\n",
      "        [2.7263, 2.7272, 2.7322,  ..., 2.7178, 2.0959, 1.9846],\n",
      "        ...,\n",
      "        [2.6936, 2.6958, 2.7178,  ..., 2.7322, 2.2472, 2.1435],\n",
      "        [1.9936, 2.0011, 2.0959,  ..., 2.2472, 2.7322, 2.7253],\n",
      "        [1.8789, 1.8866, 1.9846,  ..., 2.1435, 2.7253, 2.7322]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0052], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0052])\n",
      "iter 51 nll:366628.72610\n",
      "tensor([[2.7325, 2.7325, 2.7266,  ..., 2.6939, 1.9937, 1.8789],\n",
      "        [2.7325, 2.7325, 2.7274,  ..., 2.6960, 2.0012, 1.8867],\n",
      "        [2.7266, 2.7274, 2.7325,  ..., 2.7181, 2.0960, 1.9847],\n",
      "        ...,\n",
      "        [2.6939, 2.6960, 2.7181,  ..., 2.7325, 2.2473, 2.1436],\n",
      "        [1.9937, 2.0012, 2.0960,  ..., 2.2473, 2.7325, 2.7255],\n",
      "        [1.8789, 1.8867, 1.9847,  ..., 2.1436, 2.7255, 2.7325]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0053], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0053])\n",
      "iter 52 nll:366551.68705\n",
      "tensor([[2.7328, 2.7328, 2.7269,  ..., 2.6941, 1.9937, 1.8790],\n",
      "        [2.7328, 2.7328, 2.7277,  ..., 2.6963, 2.0013, 1.8867],\n",
      "        [2.7269, 2.7277, 2.7328,  ..., 2.7183, 2.0961, 1.9847],\n",
      "        ...,\n",
      "        [2.6941, 2.6963, 2.7183,  ..., 2.7328, 2.2474, 2.1437],\n",
      "        [1.9937, 2.0013, 2.0961,  ..., 2.2474, 2.7328, 2.7258],\n",
      "        [1.8790, 1.8867, 1.9847,  ..., 2.1437, 2.7258, 2.7328]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0054], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0054])\n",
      "iter 53 nll:366474.65845\n",
      "tensor([[2.7331, 2.7330, 2.7272,  ..., 2.6944, 1.9938, 1.8790],\n",
      "        [2.7330, 2.7331, 2.7280,  ..., 2.6966, 2.0014, 1.8868],\n",
      "        [2.7272, 2.7280, 2.7331,  ..., 2.7186, 2.0962, 1.9848],\n",
      "        ...,\n",
      "        [2.6944, 2.6966, 2.7186,  ..., 2.7331, 2.2476, 2.1439],\n",
      "        [1.9938, 2.0014, 2.0962,  ..., 2.2476, 2.7331, 2.7261],\n",
      "        [1.8790, 1.8868, 1.9848,  ..., 2.1439, 2.7261, 2.7331]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0055], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0055])\n",
      "iter 54 nll:366397.62545\n",
      "tensor([[2.7333, 2.7333, 2.7274,  ..., 2.6947, 1.9939, 1.8791],\n",
      "        [2.7333, 2.7333, 2.7283,  ..., 2.6968, 2.0014, 1.8868],\n",
      "        [2.7274, 2.7283, 2.7333,  ..., 2.7189, 2.0963, 1.9849],\n",
      "        ...,\n",
      "        [2.6947, 2.6968, 2.7189,  ..., 2.7333, 2.2477, 2.1440],\n",
      "        [1.9939, 2.0014, 2.0963,  ..., 2.2477, 2.7333, 2.7264],\n",
      "        [1.8791, 1.8868, 1.9849,  ..., 2.1440, 2.7264, 2.7333]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0056], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0056])\n",
      "iter 55 nll:366320.59290\n",
      "tensor([[2.7336, 2.7336, 2.7277,  ..., 2.6949, 1.9940, 1.8791],\n",
      "        [2.7336, 2.7336, 2.7285,  ..., 2.6971, 2.0015, 1.8869],\n",
      "        [2.7277, 2.7285, 2.7336,  ..., 2.7191, 2.0964, 1.9850],\n",
      "        ...,\n",
      "        [2.6949, 2.6971, 2.7191,  ..., 2.7336, 2.2478, 2.1441],\n",
      "        [1.9940, 2.0015, 2.0964,  ..., 2.2478, 2.7336, 2.7266],\n",
      "        [1.8791, 1.8869, 1.9850,  ..., 2.1441, 2.7266, 2.7336]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0057], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0057])\n",
      "iter 56 nll:366243.56017\n",
      "tensor([[2.7339, 2.7339, 2.7280,  ..., 2.6952, 1.9940, 1.8792],\n",
      "        [2.7339, 2.7339, 2.7288,  ..., 2.6973, 2.0016, 1.8869],\n",
      "        [2.7280, 2.7288, 2.7339,  ..., 2.7194, 2.0965, 1.9850],\n",
      "        ...,\n",
      "        [2.6952, 2.6973, 2.7194,  ..., 2.7339, 2.2480, 2.1442],\n",
      "        [1.9940, 2.0016, 2.0965,  ..., 2.2480, 2.7339, 2.7269],\n",
      "        [1.8792, 1.8869, 1.9850,  ..., 2.1442, 2.7269, 2.7339]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0058], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0058])\n",
      "iter 57 nll:366166.53249\n",
      "tensor([[2.7342, 2.7341, 2.7282,  ..., 2.6955, 1.9941, 1.8792],\n",
      "        [2.7341, 2.7342, 2.7291,  ..., 2.6976, 2.0017, 1.8870],\n",
      "        [2.7282, 2.7291, 2.7342,  ..., 2.7197, 2.0966, 1.9851],\n",
      "        ...,\n",
      "        [2.6955, 2.6976, 2.7197,  ..., 2.7342, 2.2481, 2.1443],\n",
      "        [1.9941, 2.0017, 2.0966,  ..., 2.2481, 2.7342, 2.7272],\n",
      "        [1.8792, 1.8870, 1.9851,  ..., 2.1443, 2.7272, 2.7342]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0059], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0059])\n",
      "iter 58 nll:366089.49456\n",
      "tensor([[2.7344, 2.7344, 2.7285,  ..., 2.6957, 1.9942, 1.8792],\n",
      "        [2.7344, 2.7344, 2.7294,  ..., 2.6979, 2.0018, 1.8870],\n",
      "        [2.7285, 2.7294, 2.7344,  ..., 2.7200, 2.0967, 1.9852],\n",
      "        ...,\n",
      "        [2.6957, 2.6979, 2.7200,  ..., 2.7344, 2.2483, 2.1444],\n",
      "        [1.9942, 2.0018, 2.0967,  ..., 2.2483, 2.7344, 2.7275],\n",
      "        [1.8792, 1.8870, 1.9852,  ..., 2.1444, 2.7275, 2.7344]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0060], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0060])\n",
      "iter 59 nll:366012.45224\n",
      "tensor([[2.7347, 2.7347, 2.7288,  ..., 2.6960, 1.9943, 1.8793],\n",
      "        [2.7347, 2.7347, 2.7296,  ..., 2.6981, 2.0018, 1.8871],\n",
      "        [2.7288, 2.7296, 2.7347,  ..., 2.7202, 2.0968, 1.9853],\n",
      "        ...,\n",
      "        [2.6960, 2.6981, 2.7202,  ..., 2.7347, 2.2484, 2.1445],\n",
      "        [1.9943, 2.0018, 2.0968,  ..., 2.2484, 2.7347, 2.7277],\n",
      "        [1.8793, 1.8871, 1.9853,  ..., 2.1445, 2.7277, 2.7347]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0061], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0061])\n",
      "iter 60 nll:365935.41778\n",
      "tensor([[2.7350, 2.7350, 2.7291,  ..., 2.6963, 1.9943, 1.8793],\n",
      "        [2.7350, 2.7350, 2.7299,  ..., 2.6984, 2.0019, 1.8871],\n",
      "        [2.7291, 2.7299, 2.7350,  ..., 2.7205, 2.0969, 1.9853],\n",
      "        ...,\n",
      "        [2.6963, 2.6984, 2.7205,  ..., 2.7350, 2.2485, 2.1446],\n",
      "        [1.9943, 2.0019, 2.0969,  ..., 2.2485, 2.7350, 2.7280],\n",
      "        [1.8793, 1.8871, 1.9853,  ..., 2.1446, 2.7280, 2.7350]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0062], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0062])\n",
      "iter 61 nll:365858.36879\n",
      "tensor([[2.7353, 2.7352, 2.7293,  ..., 2.6965, 1.9944, 1.8794],\n",
      "        [2.7352, 2.7353, 2.7302,  ..., 2.6987, 2.0020, 1.8872],\n",
      "        [2.7293, 2.7302, 2.7353,  ..., 2.7208, 2.0970, 1.9854],\n",
      "        ...,\n",
      "        [2.6965, 2.6987, 2.7208,  ..., 2.7353, 2.2487, 2.1448],\n",
      "        [1.9944, 2.0020, 2.0970,  ..., 2.2487, 2.7353, 2.7283],\n",
      "        [1.8794, 1.8872, 1.9854,  ..., 2.1448, 2.7283, 2.7353]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0063], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0063])\n",
      "iter 62 nll:365781.33127\n",
      "tensor([[2.7355, 2.7355, 2.7296,  ..., 2.6968, 1.9945, 1.8794],\n",
      "        [2.7355, 2.7355, 2.7305,  ..., 2.6989, 2.0021, 1.8872],\n",
      "        [2.7296, 2.7305, 2.7355,  ..., 2.7210, 2.0971, 1.9855],\n",
      "        ...,\n",
      "        [2.6968, 2.6989, 2.7210,  ..., 2.7355, 2.2488, 2.1449],\n",
      "        [1.9945, 2.0021, 2.0971,  ..., 2.2488, 2.7355, 2.7286],\n",
      "        [1.8794, 1.8872, 1.9855,  ..., 2.1449, 2.7286, 2.7355]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0064], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0064])\n",
      "iter 63 nll:365704.28878\n",
      "tensor([[2.7358, 2.7358, 2.7299,  ..., 2.6971, 1.9946, 1.8795],\n",
      "        [2.7358, 2.7358, 2.7307,  ..., 2.6992, 2.0021, 1.8873],\n",
      "        [2.7299, 2.7307, 2.7358,  ..., 2.7213, 2.0972, 1.9855],\n",
      "        ...,\n",
      "        [2.6971, 2.6992, 2.7213,  ..., 2.7358, 2.2490, 2.1450],\n",
      "        [1.9946, 2.0021, 2.0972,  ..., 2.2490, 2.7358, 2.7288],\n",
      "        [1.8795, 1.8873, 1.9855,  ..., 2.1450, 2.7288, 2.7358]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0065], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0065])\n",
      "iter 64 nll:365627.25202\n",
      "tensor([[2.7361, 2.7361, 2.7302,  ..., 2.6973, 1.9946, 1.8795],\n",
      "        [2.7361, 2.7361, 2.7310,  ..., 2.6995, 2.0022, 1.8873],\n",
      "        [2.7302, 2.7310, 2.7361,  ..., 2.7216, 2.0973, 1.9856],\n",
      "        ...,\n",
      "        [2.6973, 2.6995, 2.7216,  ..., 2.7361, 2.2491, 2.1451],\n",
      "        [1.9946, 2.0022, 2.0973,  ..., 2.2491, 2.7361, 2.7291],\n",
      "        [1.8795, 1.8873, 1.9856,  ..., 2.1451, 2.7291, 2.7361]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0066], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0066])\n",
      "iter 65 nll:365550.20845\n",
      "tensor([[2.7364, 2.7363, 2.7304,  ..., 2.6976, 1.9947, 1.8796],\n",
      "        [2.7363, 2.7364, 2.7313,  ..., 2.6997, 2.0023, 1.8874],\n",
      "        [2.7304, 2.7313, 2.7364,  ..., 2.7219, 2.0974, 1.9857],\n",
      "        ...,\n",
      "        [2.6976, 2.6997, 2.7219,  ..., 2.7364, 2.2492, 2.1452],\n",
      "        [1.9947, 2.0023, 2.0974,  ..., 2.2492, 2.7364, 2.7294],\n",
      "        [1.8796, 1.8874, 1.9857,  ..., 2.1452, 2.7294, 2.7364]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0067], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0067])\n",
      "iter 66 nll:365473.16937\n",
      "tensor([[2.7367, 2.7366, 2.7307,  ..., 2.6978, 1.9948, 1.8796],\n",
      "        [2.7366, 2.7367, 2.7316,  ..., 2.7000, 2.0024, 1.8874],\n",
      "        [2.7307, 2.7316, 2.7367,  ..., 2.7221, 2.0975, 1.9858],\n",
      "        ...,\n",
      "        [2.6978, 2.7000, 2.7221,  ..., 2.7367, 2.2494, 2.1453],\n",
      "        [1.9948, 2.0024, 2.0975,  ..., 2.2494, 2.7367, 2.7297],\n",
      "        [1.8796, 1.8874, 1.9858,  ..., 2.1453, 2.7297, 2.7367]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0068], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0068])\n",
      "iter 67 nll:365396.11308\n",
      "tensor([[2.7369, 2.7369, 2.7310,  ..., 2.6981, 1.9949, 1.8797],\n",
      "        [2.7369, 2.7369, 2.7318,  ..., 2.7003, 2.0024, 1.8875],\n",
      "        [2.7310, 2.7318, 2.7369,  ..., 2.7224, 2.0976, 1.9858],\n",
      "        ...,\n",
      "        [2.6981, 2.7003, 2.7224,  ..., 2.7369, 2.2495, 2.1454],\n",
      "        [1.9949, 2.0024, 2.0976,  ..., 2.2495, 2.7369, 2.7299],\n",
      "        [1.8797, 1.8875, 1.9858,  ..., 2.1454, 2.7299, 2.7369]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0069], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0069])\n",
      "iter 68 nll:365319.06435\n",
      "tensor([[2.7372, 2.7372, 2.7313,  ..., 2.6984, 1.9949, 1.8797],\n",
      "        [2.7372, 2.7372, 2.7321,  ..., 2.7005, 2.0025, 1.8875],\n",
      "        [2.7313, 2.7321, 2.7372,  ..., 2.7227, 2.0977, 1.9859],\n",
      "        ...,\n",
      "        [2.6984, 2.7005, 2.7227,  ..., 2.7372, 2.2496, 2.1455],\n",
      "        [1.9949, 2.0025, 2.0977,  ..., 2.2496, 2.7372, 2.7302],\n",
      "        [1.8797, 1.8875, 1.9859,  ..., 2.1455, 2.7302, 2.7372]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0070], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0070])\n",
      "iter 69 nll:365242.02638\n",
      "tensor([[2.7375, 2.7375, 2.7315,  ..., 2.6986, 1.9950, 1.8798],\n",
      "        [2.7375, 2.7375, 2.7324,  ..., 2.7008, 2.0026, 1.8876],\n",
      "        [2.7315, 2.7324, 2.7375,  ..., 2.7230, 2.0978, 1.9860],\n",
      "        ...,\n",
      "        [2.6986, 2.7008, 2.7230,  ..., 2.7375, 2.2498, 2.1456],\n",
      "        [1.9950, 2.0026, 2.0978,  ..., 2.2498, 2.7375, 2.7305],\n",
      "        [1.8798, 1.8876, 1.9860,  ..., 2.1456, 2.7305, 2.7375]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0071], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0071])\n",
      "iter 70 nll:365164.97155\n",
      "tensor([[2.7378, 2.7377, 2.7318,  ..., 2.6989, 1.9951, 1.8798],\n",
      "        [2.7377, 2.7378, 2.7327,  ..., 2.7011, 2.0027, 1.8876],\n",
      "        [2.7318, 2.7327, 2.7378,  ..., 2.7232, 2.0979, 1.9861],\n",
      "        ...,\n",
      "        [2.6989, 2.7011, 2.7232,  ..., 2.7378, 2.2499, 2.1458],\n",
      "        [1.9951, 2.0027, 2.0979,  ..., 2.2499, 2.7378, 2.7308],\n",
      "        [1.8798, 1.8876, 1.9861,  ..., 2.1458, 2.7308, 2.7378]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0072], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0072])\n",
      "iter 71 nll:365087.92400\n",
      "tensor([[2.7380, 2.7380, 2.7321,  ..., 2.6992, 1.9952, 1.8799],\n",
      "        [2.7380, 2.7380, 2.7329,  ..., 2.7013, 2.0028, 1.8877],\n",
      "        [2.7321, 2.7329, 2.7380,  ..., 2.7235, 2.0980, 1.9861],\n",
      "        ...,\n",
      "        [2.6992, 2.7013, 2.7235,  ..., 2.7380, 2.2501, 2.1459],\n",
      "        [1.9952, 2.0028, 2.0980,  ..., 2.2501, 2.7380, 2.7310],\n",
      "        [1.8799, 1.8877, 1.9861,  ..., 2.1459, 2.7310, 2.7380]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0073], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0073])\n",
      "iter 72 nll:365010.86956\n",
      "tensor([[2.7383, 2.7383, 2.7324,  ..., 2.6994, 1.9952, 1.8799],\n",
      "        [2.7383, 2.7383, 2.7332,  ..., 2.7016, 2.0028, 1.8877],\n",
      "        [2.7324, 2.7332, 2.7383,  ..., 2.7238, 2.0981, 1.9862],\n",
      "        ...,\n",
      "        [2.6994, 2.7016, 2.7238,  ..., 2.7383, 2.2502, 2.1460],\n",
      "        [1.9952, 2.0028, 2.0981,  ..., 2.2502, 2.7383, 2.7313],\n",
      "        [1.8799, 1.8877, 1.9862,  ..., 2.1460, 2.7313, 2.7383]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0074], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0074])\n",
      "iter 73 nll:364933.82307\n",
      "tensor([[2.7386, 2.7386, 2.7326,  ..., 2.6997, 1.9953, 1.8800],\n",
      "        [2.7386, 2.7386, 2.7335,  ..., 2.7019, 2.0029, 1.8878],\n",
      "        [2.7326, 2.7335, 2.7386,  ..., 2.7240, 2.0982, 1.9863],\n",
      "        ...,\n",
      "        [2.6997, 2.7019, 2.7240,  ..., 2.7386, 2.2503, 2.1461],\n",
      "        [1.9953, 2.0029, 2.0982,  ..., 2.2503, 2.7386, 2.7316],\n",
      "        [1.8800, 1.8878, 1.9863,  ..., 2.1461, 2.7316, 2.7386]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0075], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0075])\n",
      "iter 74 nll:364856.76455\n",
      "tensor([[2.7389, 2.7388, 2.7329,  ..., 2.7000, 1.9954, 1.8800],\n",
      "        [2.7388, 2.7389, 2.7338,  ..., 2.7021, 2.0030, 1.8878],\n",
      "        [2.7329, 2.7338, 2.7389,  ..., 2.7243, 2.0983, 1.9863],\n",
      "        ...,\n",
      "        [2.7000, 2.7021, 2.7243,  ..., 2.7389, 2.2505, 2.1462],\n",
      "        [1.9954, 2.0030, 2.0983,  ..., 2.2505, 2.7389, 2.7319],\n",
      "        [1.8800, 1.8878, 1.9863,  ..., 2.1462, 2.7319, 2.7389]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0076], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0076])\n",
      "iter 75 nll:364779.70690\n",
      "tensor([[2.7391, 2.7391, 2.7332,  ..., 2.7002, 1.9955, 1.8801],\n",
      "        [2.7391, 2.7391, 2.7340,  ..., 2.7024, 2.0031, 1.8879],\n",
      "        [2.7332, 2.7340, 2.7391,  ..., 2.7246, 2.0984, 1.9864],\n",
      "        ...,\n",
      "        [2.7002, 2.7024, 2.7246,  ..., 2.7391, 2.2506, 2.1463],\n",
      "        [1.9955, 2.0031, 2.0984,  ..., 2.2506, 2.7391, 2.7321],\n",
      "        [1.8801, 1.8879, 1.9864,  ..., 2.1463, 2.7321, 2.7391]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0077], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0077])\n",
      "iter 76 nll:364702.65140\n",
      "tensor([[2.7394, 2.7394, 2.7335,  ..., 2.7005, 1.9955, 1.8801],\n",
      "        [2.7394, 2.7394, 2.7343,  ..., 2.7027, 2.0031, 1.8879],\n",
      "        [2.7335, 2.7343, 2.7394,  ..., 2.7249, 2.0985, 1.9865],\n",
      "        ...,\n",
      "        [2.7005, 2.7027, 2.7249,  ..., 2.7394, 2.2508, 2.1464],\n",
      "        [1.9955, 2.0031, 2.0985,  ..., 2.2508, 2.7394, 2.7324],\n",
      "        [1.8801, 1.8879, 1.9865,  ..., 2.1464, 2.7324, 2.7394]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0078], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0078])\n",
      "iter 77 nll:364625.59601\n",
      "tensor([[2.7397, 2.7397, 2.7338,  ..., 2.7008, 1.9956, 1.8802],\n",
      "        [2.7397, 2.7397, 2.7346,  ..., 2.7029, 2.0032, 1.8880],\n",
      "        [2.7338, 2.7346, 2.7397,  ..., 2.7251, 2.0986, 1.9866],\n",
      "        ...,\n",
      "        [2.7008, 2.7029, 2.7251,  ..., 2.7397, 2.2509, 2.1465],\n",
      "        [1.9956, 2.0032, 2.0986,  ..., 2.2509, 2.7397, 2.7327],\n",
      "        [1.8802, 1.8880, 1.9866,  ..., 2.1465, 2.7327, 2.7397]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0079], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0079])\n",
      "iter 78 nll:364548.54700\n",
      "tensor([[2.7400, 2.7399, 2.7340,  ..., 2.7010, 1.9957, 1.8802],\n",
      "        [2.7399, 2.7400, 2.7349,  ..., 2.7032, 2.0033, 1.8880],\n",
      "        [2.7340, 2.7349, 2.7400,  ..., 2.7254, 2.0987, 1.9866],\n",
      "        ...,\n",
      "        [2.7010, 2.7032, 2.7254,  ..., 2.7400, 2.2510, 2.1467],\n",
      "        [1.9957, 2.0033, 2.0987,  ..., 2.2510, 2.7400, 2.7330],\n",
      "        [1.8802, 1.8880, 1.9866,  ..., 2.1467, 2.7330, 2.7400]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0080], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0080])\n",
      "iter 79 nll:364471.47901\n",
      "tensor([[2.7403, 2.7402, 2.7343,  ..., 2.7013, 1.9958, 1.8803],\n",
      "        [2.7402, 2.7403, 2.7351,  ..., 2.7035, 2.0034, 1.8881],\n",
      "        [2.7343, 2.7351, 2.7403,  ..., 2.7257, 2.0988, 1.9867],\n",
      "        ...,\n",
      "        [2.7013, 2.7035, 2.7257,  ..., 2.7403, 2.2512, 2.1468],\n",
      "        [1.9958, 2.0034, 2.0988,  ..., 2.2512, 2.7403, 2.7332],\n",
      "        [1.8803, 1.8881, 1.9867,  ..., 2.1468, 2.7332, 2.7403]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0081], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0081])\n",
      "iter 80 nll:364394.42472\n",
      "tensor([[2.7405, 2.7405, 2.7346,  ..., 2.7016, 1.9958, 1.8803],\n",
      "        [2.7405, 2.7405, 2.7354,  ..., 2.7037, 2.0034, 1.8881],\n",
      "        [2.7346, 2.7354, 2.7405,  ..., 2.7260, 2.0989, 1.9868],\n",
      "        ...,\n",
      "        [2.7016, 2.7037, 2.7260,  ..., 2.7405, 2.2513, 2.1469],\n",
      "        [1.9958, 2.0034, 2.0989,  ..., 2.2513, 2.7405, 2.7335],\n",
      "        [1.8803, 1.8881, 1.9868,  ..., 2.1469, 2.7335, 2.7405]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0082], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0082])\n",
      "iter 81 nll:364317.35808\n",
      "tensor([[2.7408, 2.7408, 2.7349,  ..., 2.7018, 1.9959, 1.8804],\n",
      "        [2.7408, 2.7408, 2.7357,  ..., 2.7040, 2.0035, 1.8882],\n",
      "        [2.7349, 2.7357, 2.7408,  ..., 2.7262, 2.0990, 1.9869],\n",
      "        ...,\n",
      "        [2.7018, 2.7040, 2.7262,  ..., 2.7408, 2.2515, 2.1470],\n",
      "        [1.9959, 2.0035, 2.0990,  ..., 2.2515, 2.7408, 2.7338],\n",
      "        [1.8804, 1.8882, 1.9869,  ..., 2.1470, 2.7338, 2.7408]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0083], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0083])\n",
      "iter 82 nll:364240.29055\n",
      "tensor([[2.7411, 2.7411, 2.7351,  ..., 2.7021, 1.9960, 1.8804],\n",
      "        [2.7411, 2.7411, 2.7360,  ..., 2.7043, 2.0036, 1.8882],\n",
      "        [2.7351, 2.7360, 2.7411,  ..., 2.7265, 2.0991, 1.9869],\n",
      "        ...,\n",
      "        [2.7021, 2.7043, 2.7265,  ..., 2.7411, 2.2516, 2.1471],\n",
      "        [1.9960, 2.0036, 2.0991,  ..., 2.2516, 2.7411, 2.7341],\n",
      "        [1.8804, 1.8882, 1.9869,  ..., 2.1471, 2.7341, 2.7411]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0084], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0084])\n",
      "iter 83 nll:364163.22905\n",
      "tensor([[2.7414, 2.7413, 2.7354,  ..., 2.7024, 1.9961, 1.8805],\n",
      "        [2.7413, 2.7414, 2.7362,  ..., 2.7045, 2.0037, 1.8883],\n",
      "        [2.7354, 2.7362, 2.7414,  ..., 2.7268, 2.0992, 1.9870],\n",
      "        ...,\n",
      "        [2.7024, 2.7045, 2.7268,  ..., 2.7414, 2.2517, 2.1472],\n",
      "        [1.9961, 2.0037, 2.0992,  ..., 2.2517, 2.7414, 2.7343],\n",
      "        [1.8805, 1.8883, 1.9870,  ..., 2.1472, 2.7343, 2.7414]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0085], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0085])\n",
      "iter 84 nll:364086.16217\n",
      "tensor([[2.7416, 2.7416, 2.7357,  ..., 2.7026, 1.9961, 1.8805],\n",
      "        [2.7416, 2.7416, 2.7365,  ..., 2.7048, 2.0038, 1.8883],\n",
      "        [2.7357, 2.7365, 2.7416,  ..., 2.7271, 2.0993, 1.9871],\n",
      "        ...,\n",
      "        [2.7026, 2.7048, 2.7271,  ..., 2.7416, 2.2519, 2.1473],\n",
      "        [1.9961, 2.0038, 2.0993,  ..., 2.2519, 2.7416, 2.7346],\n",
      "        [1.8805, 1.8883, 1.9871,  ..., 2.1473, 2.7346, 2.7416]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0086], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0086])\n",
      "iter 85 nll:364009.10192\n",
      "tensor([[2.7419, 2.7419, 2.7360,  ..., 2.7029, 1.9962, 1.8806],\n",
      "        [2.7419, 2.7419, 2.7368,  ..., 2.7051, 2.0038, 1.8884],\n",
      "        [2.7360, 2.7368, 2.7419,  ..., 2.7273, 2.0994, 1.9872],\n",
      "        ...,\n",
      "        [2.7029, 2.7051, 2.7273,  ..., 2.7419, 2.2520, 2.1474],\n",
      "        [1.9962, 2.0038, 2.0994,  ..., 2.2520, 2.7419, 2.7349],\n",
      "        [1.8806, 1.8884, 1.9872,  ..., 2.1474, 2.7349, 2.7419]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0087], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0087])\n",
      "iter 86 nll:363932.02084\n",
      "tensor([[2.7422, 2.7422, 2.7362,  ..., 2.7032, 1.9963, 1.8806],\n",
      "        [2.7422, 2.7422, 2.7371,  ..., 2.7053, 2.0039, 1.8884],\n",
      "        [2.7362, 2.7371, 2.7422,  ..., 2.7276, 2.0995, 1.9872],\n",
      "        ...,\n",
      "        [2.7032, 2.7053, 2.7276,  ..., 2.7422, 2.2522, 2.1476],\n",
      "        [1.9963, 2.0039, 2.0995,  ..., 2.2522, 2.7422, 2.7352],\n",
      "        [1.8806, 1.8884, 1.9872,  ..., 2.1476, 2.7352, 2.7422]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0088], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0088])\n",
      "iter 87 nll:363854.96154\n",
      "tensor([[2.7425, 2.7425, 2.7365,  ..., 2.7034, 1.9964, 1.8806],\n",
      "        [2.7425, 2.7425, 2.7374,  ..., 2.7056, 2.0040, 1.8885],\n",
      "        [2.7365, 2.7374, 2.7425,  ..., 2.7279, 2.0996, 1.9873],\n",
      "        ...,\n",
      "        [2.7034, 2.7056, 2.7279,  ..., 2.7425, 2.2523, 2.1477],\n",
      "        [1.9964, 2.0040, 2.0996,  ..., 2.2523, 2.7425, 2.7354],\n",
      "        [1.8806, 1.8885, 1.9873,  ..., 2.1477, 2.7354, 2.7425]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0089], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0089])\n",
      "iter 88 nll:363777.88021\n",
      "tensor([[2.7428, 2.7427, 2.7368,  ..., 2.7037, 1.9964, 1.8807],\n",
      "        [2.7427, 2.7428, 2.7376,  ..., 2.7059, 2.0041, 1.8885],\n",
      "        [2.7368, 2.7376, 2.7428,  ..., 2.7282, 2.0997, 1.9874],\n",
      "        ...,\n",
      "        [2.7037, 2.7059, 2.7282,  ..., 2.7428, 2.2524, 2.1478],\n",
      "        [1.9964, 2.0041, 2.0997,  ..., 2.2524, 2.7428, 2.7357],\n",
      "        [1.8807, 1.8885, 1.9874,  ..., 2.1478, 2.7357, 2.7428]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0090], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0090])\n",
      "iter 89 nll:363700.81418\n",
      "tensor([[2.7430, 2.7430, 2.7371,  ..., 2.7040, 1.9965, 1.8807],\n",
      "        [2.7430, 2.7430, 2.7379,  ..., 2.7061, 2.0041, 1.8886],\n",
      "        [2.7371, 2.7379, 2.7430,  ..., 2.7284, 2.0998, 1.9874],\n",
      "        ...,\n",
      "        [2.7040, 2.7061, 2.7284,  ..., 2.7430, 2.2526, 2.1479],\n",
      "        [1.9965, 2.0041, 2.0998,  ..., 2.2526, 2.7430, 2.7360],\n",
      "        [1.8807, 1.8886, 1.9874,  ..., 2.1479, 2.7360, 2.7430]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0091], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0091])\n",
      "iter 90 nll:363623.74543\n",
      "tensor([[2.7433, 2.7433, 2.7373,  ..., 2.7042, 1.9966, 1.8808],\n",
      "        [2.7433, 2.7433, 2.7382,  ..., 2.7064, 2.0042, 1.8886],\n",
      "        [2.7373, 2.7382, 2.7433,  ..., 2.7287, 2.0999, 1.9875],\n",
      "        ...,\n",
      "        [2.7042, 2.7064, 2.7287,  ..., 2.7433, 2.2527, 2.1480],\n",
      "        [1.9966, 2.0042, 2.0999,  ..., 2.2527, 2.7433, 2.7363],\n",
      "        [1.8808, 1.8886, 1.9875,  ..., 2.1480, 2.7363, 2.7433]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0092], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0092])\n",
      "iter 91 nll:363546.66716\n",
      "tensor([[2.7436, 2.7436, 2.7376,  ..., 2.7045, 1.9967, 1.8808],\n",
      "        [2.7436, 2.7436, 2.7385,  ..., 2.7067, 2.0043, 1.8887],\n",
      "        [2.7376, 2.7385, 2.7436,  ..., 2.7290, 2.1000, 1.9876],\n",
      "        ...,\n",
      "        [2.7045, 2.7067, 2.7290,  ..., 2.7436, 2.2529, 2.1481],\n",
      "        [1.9967, 2.0043, 2.1000,  ..., 2.2529, 2.7436, 2.7365],\n",
      "        [1.8808, 1.8887, 1.9876,  ..., 2.1481, 2.7365, 2.7436]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0093], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0093])\n",
      "iter 92 nll:363469.60107\n",
      "tensor([[2.7439, 2.7438, 2.7379,  ..., 2.7048, 1.9967, 1.8809],\n",
      "        [2.7438, 2.7439, 2.7387,  ..., 2.7069, 2.0044, 1.8887],\n",
      "        [2.7379, 2.7387, 2.7439,  ..., 2.7292, 2.1001, 1.9877],\n",
      "        ...,\n",
      "        [2.7048, 2.7069, 2.7292,  ..., 2.7439, 2.2530, 2.1482],\n",
      "        [1.9967, 2.0044, 2.1001,  ..., 2.2530, 2.7439, 2.7368],\n",
      "        [1.8809, 1.8887, 1.9877,  ..., 2.1482, 2.7368, 2.7439]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0094], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0094])\n",
      "iter 93 nll:363392.51805\n",
      "tensor([[2.7442, 2.7441, 2.7382,  ..., 2.7050, 1.9968, 1.8809],\n",
      "        [2.7441, 2.7442, 2.7390,  ..., 2.7072, 2.0044, 1.8888],\n",
      "        [2.7382, 2.7390, 2.7442,  ..., 2.7295, 2.1002, 1.9877],\n",
      "        ...,\n",
      "        [2.7050, 2.7072, 2.7295,  ..., 2.7442, 2.2531, 2.1483],\n",
      "        [1.9968, 2.0044, 2.1002,  ..., 2.2531, 2.7442, 2.7371],\n",
      "        [1.8809, 1.8888, 1.9877,  ..., 2.1483, 2.7371, 2.7442]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0095], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0095])\n",
      "iter 94 nll:363315.43590\n",
      "tensor([[2.7444, 2.7444, 2.7385,  ..., 2.7053, 1.9969, 1.8810],\n",
      "        [2.7444, 2.7444, 2.7393,  ..., 2.7075, 2.0045, 1.8888],\n",
      "        [2.7385, 2.7393, 2.7444,  ..., 2.7298, 2.1003, 1.9878],\n",
      "        ...,\n",
      "        [2.7053, 2.7075, 2.7298,  ..., 2.7444, 2.2533, 2.1485],\n",
      "        [1.9969, 2.0045, 2.1003,  ..., 2.2533, 2.7444, 2.7374],\n",
      "        [1.8810, 1.8888, 1.9878,  ..., 2.1485, 2.7374, 2.7444]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0096], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0096])\n",
      "iter 95 nll:363238.36207\n",
      "tensor([[2.7447, 2.7447, 2.7387,  ..., 2.7056, 1.9970, 1.8810],\n",
      "        [2.7447, 2.7447, 2.7396,  ..., 2.7077, 2.0046, 1.8889],\n",
      "        [2.7387, 2.7396, 2.7447,  ..., 2.7301, 2.1004, 1.9879],\n",
      "        ...,\n",
      "        [2.7056, 2.7077, 2.7301,  ..., 2.7447, 2.2534, 2.1486],\n",
      "        [1.9970, 2.0046, 2.1004,  ..., 2.2534, 2.7447, 2.7377],\n",
      "        [1.8810, 1.8889, 1.9879,  ..., 2.1486, 2.7377, 2.7447]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0097], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0097])\n",
      "iter 96 nll:363161.27413\n",
      "tensor([[2.7450, 2.7450, 2.7390,  ..., 2.7058, 1.9970, 1.8811],\n",
      "        [2.7450, 2.7450, 2.7398,  ..., 2.7080, 2.0047, 1.8889],\n",
      "        [2.7390, 2.7398, 2.7450,  ..., 2.7303, 2.1005, 1.9880],\n",
      "        ...,\n",
      "        [2.7058, 2.7080, 2.7303,  ..., 2.7450, 2.2536, 2.1487],\n",
      "        [1.9970, 2.0047, 2.1005,  ..., 2.2536, 2.7450, 2.7379],\n",
      "        [1.8811, 1.8889, 1.9880,  ..., 2.1487, 2.7379, 2.7450]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0098], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0098])\n",
      "iter 97 nll:363084.20002\n",
      "tensor([[2.7453, 2.7452, 2.7393,  ..., 2.7061, 1.9971, 1.8811],\n",
      "        [2.7452, 2.7453, 2.7401,  ..., 2.7083, 2.0048, 1.8890],\n",
      "        [2.7393, 2.7401, 2.7453,  ..., 2.7306, 2.1006, 1.9880],\n",
      "        ...,\n",
      "        [2.7061, 2.7083, 2.7306,  ..., 2.7453, 2.2537, 2.1488],\n",
      "        [1.9971, 2.0048, 2.1006,  ..., 2.2537, 2.7453, 2.7382],\n",
      "        [1.8811, 1.8890, 1.9880,  ..., 2.1488, 2.7382, 2.7453]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0099], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0099])\n",
      "iter 98 nll:363007.11440\n",
      "tensor([[2.7456, 2.7455, 2.7396,  ..., 2.7064, 1.9972, 1.8812],\n",
      "        [2.7455, 2.7456, 2.7404,  ..., 2.7085, 2.0048, 1.8890],\n",
      "        [2.7396, 2.7404, 2.7456,  ..., 2.7309, 2.1007, 1.9881],\n",
      "        ...,\n",
      "        [2.7064, 2.7085, 2.7309,  ..., 2.7456, 2.2538, 2.1489],\n",
      "        [1.9972, 2.0048, 2.1007,  ..., 2.2538, 2.7456, 2.7385],\n",
      "        [1.8812, 1.8890, 1.9881,  ..., 2.1489, 2.7385, 2.7456]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "length_scales: tensor([-0.0100], dtype=torch.float64)\n",
      "signal_variance: tensor([0.0100])\n",
      "iter 99 nll:362930.02638\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_adam(xtr, ytr, kernel, log_beta, niteration=100,lr=0.0001)\n",
    "end_time = time.time()\n",
    "cg_gp_time=end_time-start_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T03:59:47.797769900Z",
     "start_time": "2024-07-25T03:59:21.495707200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    start_time = time.time()\n",
    "    train_adam(xtr, ytr, kernel, log_beta, niteration=100,lr=0.1)\n",
    "    end_time = time.time()\n",
    "    cg_gp_time=end_time-start_time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ypred, yvar = forward(xtr, ytr, xte, kernel,log_beta)\n",
    "plt.errorbar(xte.cpu().numpy().reshape(100), ypred.detach().cpu().numpy().reshape(100),\n",
    "             yerr=yvar.cpu().sqrt().squeeze().detach().numpy(), fmt='r-.', alpha=0.2)\n",
    "plt.plot(xtr.cpu().numpy(), ytr.cpu().numpy(), 'b+')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T00:56:01.418162200Z",
     "start_time": "2024-07-09T00:56:00.644677900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 nll:1992.60405\n",
      "iter 10 nll:1004.92647\n",
      "iter 20 nll:256.53823\n",
      "iter 30 nll:-130.12748\n",
      "iter 40 nll:-119.43786\n",
      "iter 50 nll:-138.47822\n",
      "iter 60 nll:-151.89502\n",
      "iter 70 nll:-150.11973\n",
      "iter 80 nll:-152.93419\n",
      "iter 90 nll:-152.62457\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xtr,ytr=xtr.cpu(),ytr.cpu()\n",
    "model=cigp(xtr,ytr)\n",
    "model.train_adam(100,0.1)\n",
    "end_time = time.time()\n",
    "standard_gp_time=end_time-start_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T00:44:50.395376400Z",
     "start_time": "2024-07-05T00:44:08.146128400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.24608373641968\n"
     ]
    }
   ],
   "source": [
    "print(standard_gp_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T00:45:05.818294600Z",
     "start_time": "2024-07-05T00:45:05.801377600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
